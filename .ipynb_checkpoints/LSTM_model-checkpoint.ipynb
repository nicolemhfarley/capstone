{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from statsmodels.graphics import tsaplots\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.arima_model import ARIMA, ARIMAResults, ARMA\n",
    "from statsmodels.tsa.arima_process import ArmaProcess\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "from scipy import signal\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import pyflux as pf\n",
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "np.random.seed(42)\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LSTM_functions import split_and_reshape_data, fit_sequential_LSTM, get_LSTM_predictions_and_inversions,\\\n",
    "inverse_transform, calculate_RMSE, prep_predictions_for_plotting, plot_data_LSTM_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeseries_functions import index_to_datetime, downsample_data_week, weekly_resample, plot_series,\\\n",
    "plot_series_save_fig, plot_series_and_differences, run_augmented_Dickey_Fuller_test, \\\n",
    "plot_autocorrelation, plot_partial_autocorrelation, plot_decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeseries_functions import make_col_vector, make_design_matrix, fit_linear_trend,\\\n",
    "plot_trend_data, plot_linear_trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.rcParams.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dr = pd.read_csv('all_dr_hours.csv', index_col=0, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_RN_PA = pd.read_csv('all_RN_PA_hours.csv', index_col=0, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_therapist = pd.read_csv('all_therapist_hours.csv',index_col=0, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dr.index = pd.to_datetime(all_dr.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### visualize major holidays and their effects on series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "additional dips seen around May-June, September"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# try with just Dr data\n",
    "new_years = ['2016-01-01', '2017-01-01', '2018-01-01']\n",
    "fourth_of_july = ['2015-07-04', '2016-07-04', '2017-07-04']\n",
    "Christmas = ['2015-12-15', '2016-12-25', '2017-12-25']\n",
    "Thanksgiving = ['2015-11-26', '2016-11-24', '2017-11-23']\n",
    "holidays = ['2016-01-01', '2017-01-01', '2018-01-01','2015-07-04', '2016-07-04', '2017-07-04',\\\n",
    "            '2015-12-15', '2016-12-25', '2017-12-25', '2015-11-26', '2016-11-24', '2017-11-23']\n",
    "\n",
    "fig = plot_series_save_fig(all_dr, xlabel='Date', ylabel='Hours per Week', plot_name='Doctors Hourly with Holidays (red)',\\\n",
    "            v_lines=holidays, figsize=(12,6), figname=\"dr_data_w_holidays.pdf\")\n",
    "# plt.savefig(figname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "all_RN_PA.index = pd.to_datetime(all_RN_PA.index)\n",
    "plot_series_save_fig(all_RN_PA, xlabel='Date', ylabel='Hours per Week', plot_name='RN/PA Hourly with Holidays (red)',\\\n",
    "            v_lines=holidays, figsize=(12,6), figname=\"RN_PA_data_w_holidays.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_therapist.index = pd.to_datetime(all_therapist.index)\n",
    "plot_series_save_fig(all_therapist, xlabel='Date', ylabel='Hours per Week', plot_name='Therapists Hourly with Holidays (red)',\\\n",
    "            v_lines=holidays, figsize=(12,6), figname=\"therapist_data_w_holidays.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Long Short-Term Memory network (LSTM)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "see: https://machinelearningmastery.com/time-series-prediction-lstm-recurrent-neural-networks-python-keras/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = all_dr.values\n",
    "# reshape to 2D array\n",
    "data = data.reshape(-1,1)\n",
    "# scale/normalize data\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "data = scaler.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into training and test sets\n",
    "train_size = int(len(data) * 0.67)\n",
    "test_size = len(data) - train_size\n",
    "train, test = data[0:train_size,:], data[train_size:len(data),:]\n",
    "train, test = data[0:train_size,:], data[train_size:len(data),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert data values into dataset matrix\n",
    "def create_dataset(data, num_steps=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(data)-num_steps-1):\n",
    "        a = data[i:(i+num_steps),0]\n",
    "        dataX.append(a)\n",
    "        dataY.append(data[i + num_steps, 0])\n",
    "    return np.array(dataX), np.array(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_steps=1\n",
    "trainX, trainY = create_dataset(train, num_steps)\n",
    "testX, testY = create_dataset(test, num_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainY"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# LSTM network expects the input data (X) to be provided with a specific\n",
    "# array structure in the form of: [samples, time steps, features]\n",
    "# reshape data to be [samples, time steps, features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "testX = np.reshape(testX, (testX.shape[0], 1, testX.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testX.shape, trainX.shape, testY.shape, trainY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create and fit LSTM network\n",
    "model = Sequential()\n",
    "model.add(LSTM(4, input_shape=(1, num_steps)))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(trainX, trainY, epochs=100, batch_size=1, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get predictions\n",
    "trainPredict = model.predict(trainX)\n",
    "testPredict = model.predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# invert predictions\n",
    "trainPredict = scaler.inverse_transform(trainPredict)\n",
    "trainY = scaler.inverse_transform([trainY])\n",
    "testPredict = scaler.inverse_transform(testPredict)\n",
    "testY = scaler.inverse_transform([testY])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainY.shape, testY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# calculate root mean squared error\n",
    "trainScore = math.sqrt(mean_squared_error(trainY[0], trainPredict[:,0]))\n",
    "print('Train Score: %.2f RMSE' % (trainScore))\n",
    "testScore = math.sqrt(mean_squared_error(testY[0], testPredict[:,0]))\n",
    "print('Test Score: %.2f RMSE' % (testScore))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shift train and test predictions for plotting\n",
    "trainPredictPlot = np.empty_like(data)\n",
    "trainPredictPlot[:, :] = np.nan\n",
    "trainPredictPlot[num_steps:len(trainPredict)+num_steps, :] = trainPredict\n",
    "testPredictPlot = np.empty_like(data)\n",
    "testPredictPlot[:, :] = np.nan\n",
    "testPredictPlot[len(trainPredict)+(num_steps*2)+1:len(data)-1, :] = testPredict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot baseline and predictions\n",
    "params = {'figure.figsize': [10,10],'axes.grid': False,'axes.grid.axis': 'both', 'axes.labelsize': 'Medium', 'font.size': 12.0, \\\n",
    "'lines.linewidth': 2}\n",
    "plt.rcParams.update(params)\n",
    "plt.plot(scaler.inverse_transform(data), label='actual')\n",
    "plt.plot(trainPredictPlot, linestyle='--',  label='predicted')\n",
    "plt.plot(testPredictPlot, linestyle='--', label='predicted')\n",
    "plt.xlabel('Number of Weeks')\n",
    "plt.ylabel('Hours per Week')\n",
    "plt.title('Doctors LSTM Model')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_and_reshape_data(data, split_at=0.67, num_steps=1):\n",
    "    train_size = int(len(data) * 0.67)\n",
    "    test_size = len(data) - train_size\n",
    "    train, test = data[0:train_size,:], data[train_size:len(data),:]\n",
    "    train, test = data[0:train_size,:], data[train_size:len(data),:]\n",
    "    trainX, trainY = create_dataset(train, num_steps)\n",
    "    testX, testY = create_dataset(test, num_steps)\n",
    "    trainX = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "    testX = np.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n",
    "    return trainX, trainY, testX, testY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_sequential_LSTM(trainX, trainY, add_layers=4, input_shape=(1,1),\\\n",
    "                        density=1, epochs=100, batch_size=1, optimizer='adam', verbose=2, \\\n",
    "                        loss='mean_squared_error'):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(add_layers, input_shape=input_shape))\n",
    "    model.add(Dense(density))\n",
    "    model.compile(loss=loss, optimizer=optimizer)\n",
    "    model.fit(trainX, trainY, epochs=epochs, batch_size=batch_size, verbose=verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_LSTM_predictions_and_inversions(trainX, testX):\n",
    "    \"Get predictions for training and test data\"\n",
    "    trainPredict = model.predict(trainX)\n",
    "    testPredict = model.predict(testX)\n",
    "    return trainPredict, testPredict\n",
    "\n",
    "def inverse_transform(trainY, testY, trainPredict, testPredict):  \n",
    "    \"Inverse transform train and test set pedictions\"\n",
    "    trainPredict = scaler.inverse_transform(trainPredict)\n",
    "    trainY = scaler.inverse_transform([trainY])\n",
    "    testPredict = scaler.inverse_transform(testPredict)\n",
    "    testY = scaler.inverse_transform([testY])\n",
    "    return trainY, testY, trainPredict, testPredict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_RMSE(trainY, testY, trainPredict, testPredict):\n",
    "    \"calculate root mean squared error for training and test predictions\"\n",
    "    trainScore = math.sqrt(mean_squared_error(trainY[0], trainPredict[:,0]))\n",
    "    print('Train Score: %.2f RMSE' % (trainScore))\n",
    "    testScore = math.sqrt(mean_squared_error(testY[0], testPredict[:,0]))\n",
    "    print('Test Score: %.2f RMSE' % (testScore))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_predictions_for_plotting(data, trainPredict, testPredict, num_steps=1):\n",
    "    trainPredictPlot = np.empty_like(data)\n",
    "    trainPredictPlot[:, :] = np.nan\n",
    "    trainPredictPlot[num_steps:len(trainPredict)+num_steps, :] = trainPredict\n",
    "    testPredictPlot = np.empty_like(data)\n",
    "    testPredictPlot[:, :] = np.nan\n",
    "    testPredictPlot[len(trainPredict)+(num_steps*2)+1:len(data)-1, :] = testPredict\n",
    "    return trainPredictPlot, testPredictPlot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data_LSTM_predictions(data, trainPredictPlot, testPredictPlot,\\\n",
    "                               params,title='', xlabel='', ylabel=''):\n",
    "    fig = plt.figure()\n",
    "    plt.rcParams.update(params)\n",
    "    plt.plot(scaler.inverse_transform(data), label='actual')\n",
    "    plt.plot(trainPredictPlot, linestyle='--',  label='predicted')\n",
    "    plt.plot(testPredictPlot, linestyle='--', label='predicted')\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    return "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### for RN/PA category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = all_RN_PA.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape to 2D array\n",
    "data = data.reshape(-1,1)\n",
    "# scale/normalize data\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "data = scaler.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainX, trainY, testX, testY = split_and_reshape_data(data, split_at=0.67, num_steps=1)\n",
    "\n",
    "fit_sequential_LSTM(trainX, trainY, add_layers=4, input_shape=(1,1),\\\n",
    "                        density=1, epochs=100, batch_size=1, optimizer='adam', verbose=2, \\\n",
    "                        loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainPredict, testPredict = get_LSTM_predictions_and_inversions(trainX, testX)\n",
    "\n",
    "trainY, testY, trainPredict, testPredict = inverse_transform(trainY, testY, trainPredict, testPredict)\n",
    "\n",
    "calculate_RMSE(trainY, testY, trainPredict, testPredict)\n",
    "\n",
    "trainPredictPlot, testPredictPlot = prep_predictions_for_plotting(data, trainPredict, testPredict, num_steps=1)\n",
    "\n",
    "plot_data_LSTM_predictions(data, trainPredictPlot, testPredictPlot,\\\n",
    "    params,title='RN/PA LSTM Model', xlabel='Number of Weeks', ylabel='Hours per Week')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Therapists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = all_therapist.values\n",
    "# reshape to 2D array\n",
    "data = data.reshape(-1,1)\n",
    "# scale/normalize data\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "data = scaler.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainX, trainY, testX, testY = split_and_reshape_data(data, split_at=0.67, num_steps=1)\n",
    "\n",
    "fit_sequential_LSTM(trainX, trainY, add_layers=4, input_shape=(1,1),\\\n",
    "                        density=1, epochs=100, batch_size=1, optimizer='adam', verbose=2, \\\n",
    "                        loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "trainPredict, testPredict = get_LSTM_predictions_and_inversions(trainX, testX)\n",
    "\n",
    "trainY, testY, trainPredict, testPredict = inverse_transform(trainY, testY, trainPredict, testPredict)\n",
    "\n",
    "calculate_RMSE(trainY, testY, trainPredict, testPredict)\n",
    "\n",
    "trainPredictPlot, testPredictPlot = prep_predictions_for_plotting(data, trainPredict, testPredict, num_steps=1)\n",
    "\n",
    "plot_data_LSTM_predictions(data, trainPredictPlot, testPredictPlot,\\\n",
    "    params,title='Therapists LSTM Model', xlabel='Number of Weeks', ylabel='Hours per Week')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
