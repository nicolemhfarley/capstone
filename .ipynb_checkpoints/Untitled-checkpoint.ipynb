{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.graphics import tsaplots\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.arima_model import ARIMA, ARIMAResults\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_to_datetime(series):\n",
    "    \"\"\"Converts pandas dataframe or series index to datetime\"\"\"\n",
    "    series.index = pd.to_datetime(series.index, errors='coerce')\n",
    "\n",
    "# def weekly_resample(data):\n",
    "#     \"\"\"resamples data to weekly and sums values\n",
    "#     \"\"\"\n",
    "#     data = data.resample('W-MON').sum()\n",
    "#     return data\n",
    "\n",
    "# import data from csv files for a specific provider cateogry\n",
    "def get_provider_data(csv_file, category_name):\n",
    "    appointment_df = pd.read_csv(csv_file, index_col=0)\n",
    "    # convert index to datetime if necessary\n",
    "    if type(appointment_df.index) != True:\n",
    "        index_to_datetime(appointment_df)\n",
    "    # group by specialty\n",
    "    provider = appointment_df[appointment_df['Specialty'] == category_name]\n",
    "    # convert appointment duration into hours\n",
    "    provider['Hours'] = provider['AppointmentDuration'] / 60\n",
    "    # return provider series\n",
    "    return provider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_provider_weekly_hours(provider):\n",
    "    provider_hours = provider.copy()\n",
    "    provider_hours = provider.groupby(provider.index.date)['Hours'].sum()\n",
    "    index_to_datetime(provider)\n",
    "    provider = provider.resample('W-MON').sum()\n",
    "    provider_hours = provider[1:]\n",
    "    provider_hours= provider_hours['Hours']\n",
    "    return provider_hours\n",
    "\n",
    "def get_number_unique_providers(provider):\n",
    "    num_provider = provider.copy()\n",
    "    num_provider = provider['Provider'].resample('W-MON', lambda x: x.nunique())\n",
    "    # set index to to_datetime\n",
    "    index_to_datetime(num_provider)\n",
    "    # drop incomplete first column\n",
    "    num_provider = num_provider[1:]\n",
    "    return num_provider\n",
    "\n",
    "def merge_hours_and_providers(hours, num_providers):\n",
    "    hours = hours.to_frame()\n",
    "    num_providers = num_providers.to_frame()\n",
    "    df = pd.merge(left=num_providers, right=hours, how='inner', left_index=True, right_index=True)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hours_per_provider(df):\n",
    "    df.columns = ['Number_Providers', 'Hours']\n",
    "    df['Hours_per_Provider'] = df['Hours'] / df['Number_Providers']\n",
    "    mean_hours_provider = df['Hours_per_Provider'].mean()\n",
    "    return df, mean_hours_provider\n",
    "\n",
    "def get_ARIMAX_predictions(data, order, start, end, exog=None, typ='levels'):\n",
    "    \"\"\"Get ARIMAX predictions\n",
    "    Inputs:\n",
    "        data: pandas Series\n",
    "        order: (p,d,q) format\n",
    "        start/end: (str) starting/ending dates\n",
    "        exog: data for exogenous variable as pandas series\n",
    "    Outputs:\n",
    "        data_plus_forecast: dataframe with original data and forecast plot_all_df_columns\n",
    "    \"\"\"\n",
    "    data = data.to_frame()\n",
    "    results = ARIMA(data, order=order, exog=exog).fit()\n",
    "    forecast = results.predict(start=start, end=end, exog=exog, typ=typ).to_frame()\n",
    "    data_plus_forecast = pd.merge(left=data, right=forecast, how='outer', left_index=True, right_index=True)\n",
    "    data_plus_forecast.columns = ['data', 'forecast']\n",
    "    return data_plus_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ARIMAX_forecast(csv_file, category_name, order, start_date, end_date, outfile):\n",
    "    # import provider data\n",
    "    provider = get_provider_data(csv_file, category_name)\n",
    "    # get weekly hours data\n",
    "    provider_hours = get_provider_weekly_hours(provider)\n",
    "    # get number of providers data\n",
    "    num_provider = get_number_unique_providers(provider)\n",
    "    # merge provider dataframes\n",
    "    provider = merge_hours_and_providers(provider_hours, num_provider)\n",
    "    # get hours per provider\n",
    "    provider_df, avg_provider_hours = get_hours_per_provider(provider)\n",
    "\n",
    "    forecast_df = get_ARIMAX_predictions(data=provider_hours, order=provider_order, start=start_date,\\\n",
    "     end=end_date, exog=num_provider, typ='levels')\n",
    "    forecast_df.columns = ['Hours', 'Predicted_Hours']\n",
    "    # get predicted number of providers rounded up\n",
    "    forecast_df['Predicted_Num_Providers'] = round(forecast_df['Predicted_Hours'] / avg_provider_hours)\n",
    "    # get forecast\n",
    "    forecast = forecast_df[start_date:end_date]#[['Predicted_Hours', 'Predicted_Num_Providers']]\n",
    "    # keep only date in index, drop time\n",
    "    forecast.index = forecast.index.date\n",
    "    # output to csv file\n",
    "    forecast.to_csv(outfile)\n",
    "    return forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = './data/appointments_through_04-2018.csv'\n",
    "\n",
    "provider_order = (5,1,0)\n",
    "start_date = '2015-01-19'\n",
    "end_date = '2018-09-30'\n",
    "outfile = 'test_arimax.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "provider = get_provider_data(data_file, 'doctor')\n",
    "    # get weekly hours data\n",
    "provider_hours = get_provider_weekly_hours(provider)\n",
    "    # get number of providers data\n",
    "num_provider = get_number_unique_providers(provider)\n",
    "    # merge provider dataframes\n",
    "provider = merge_hours_and_providers(provider_hours, num_provider)\n",
    "    # get hours per provider\n",
    "provider_df, avg_provider_hours = get_hours_per_provider(provider)\n",
    "\n",
    "forecast_df = get_ARIMAX_predictions(data=provider_hours, order=provider_order, start=start_date,\\\n",
    "    end=end_date, exog=num_provider, typ='levels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_df['Pred_num_providers'] = round(forecast_df['forecast'] / 19.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast = get_ARIMAX_forecast(data_file, 'doctor', (5,1,0), '2015-01-19', '2018-09-30', 'test_arimax.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "provider = get_provider_data(data_file, 'doctor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "provider_hours = get_provider_weekly_hours(provider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# provider_hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_provider = get_number_unique_providers(provider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "num_provider.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(provider_hours), type(num_provider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "provider = merge_hours_and_providers(provider_hours, num_provider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "provider.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "provider.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "provider_df, avg_provider_hours = get_hours_per_provider(provider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "provider_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_provider_hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ARIMAX_predictions(data, order, start, end, exog=None, typ='levels'):\n",
    "    \"\"\"Get ARIMAX predictions\n",
    "    Inputs:\n",
    "        data: pandas Series\n",
    "        order: (p,d,q) format\n",
    "        start/end: (str) starting/ending dates\n",
    "        exog: data for exogenous variable as pandas series\n",
    "    Outputs:\n",
    "        data_plus_forecast: dataframe with original data and forecast plot_all_df_columns\n",
    "    \"\"\"\n",
    "#     data = data.values\n",
    "    results = ARIMA(data, order=order, exog=exog).fit()\n",
    "    forecast = results.predict(start=start, end=end, exog=exog, typ=typ).to_frame()\n",
    "    data_plus_forecast = pd.merge(left=data, right=forecast, how='outer', left_index=True, right_index=True)\n",
    "    data_plus_forecast.columns = ['data', 'forecast']\n",
    "    return data_plus_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "forecast = get_ARIMAX_predictions(provider_hours, (5,1,0), '2015-01-19', '2018-09-30', num_provider, typ='levels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_df = get_ARIMAX_predictions(data=provider_hours, order=provider_order, start=start_date,\\\n",
    "     end=end_date, exog=num_provider, typ='levels')\n",
    "forecast_df.columns = ['Hours', 'Predicted_Hours']\n",
    "    # get predicted number of providers rounded up\n",
    "forecast_df['Predicted_Num_Providers'] = round(forecast_df['Predicted_Hours'] / avg_provider_hours)\n",
    "    # get forecast\n",
    "forecast = forecast_df[start_date:end_date]#[['Predicted_Hours', 'Predicted_Num_Providers']]\n",
    "    # keep only date in index, drop time\n",
    "forecast.index = forecast.index.date\n",
    "    # output to csv file\n",
    "forecast.to_csv(outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from fbprophet import Prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_to_datetime(series):\n",
    "    \"\"\"Converts pandas dataframe or series index to datetime\"\"\"\n",
    "    series.index = pd.to_datetime(series.index, errors='coerce')\n",
    "\n",
    "# import data from csv files for a specific provider cateogry\n",
    "def get_cleaned_provider_data(csv_file, category_name):\n",
    "    appointment_df = pd.read_csv(csv_file, index_col=0)\n",
    "    # convert index to datetime if necessary\n",
    "    if type(appointment_df.index) != True:\n",
    "        index_to_datetime(appointment_df)\n",
    "    # group by specialty\n",
    "    provider = appointment_df[appointment_df['Specialty'] == category_name]\n",
    "    # convert appointment duration into hours\n",
    "    provider['Hours'] = provider['AppointmentDuration'] / 60\n",
    "    # return provider series\n",
    "    return provider\n",
    "\n",
    "def get_provider_weekly_hours(provider):\n",
    "    provider_hours = provider.copy()\n",
    "    provider_hours = provider.groupby(provider.index.date)['Hours'].sum()\n",
    "    index_to_datetime(provider)\n",
    "    provider = provider.resample('W-MON').sum()\n",
    "    provider_hours = provider[1:]\n",
    "    provider_hours = provider_hours['Hours']\n",
    "    return provider_hours\n",
    "\n",
    "def get_number_unique_providers(provider):\n",
    "    num_provider = provider.copy()\n",
    "    num_provider = provider['Provider'].resample('W-MON', lambda x: x.nunique())\n",
    "    # set index to to_datetime\n",
    "    index_to_datetime(num_provider)\n",
    "    # drop incomplete first column\n",
    "    num_provider = num_provider[1:]\n",
    "    return num_provider\n",
    "\n",
    "def merge_hours_and_providers(hours, num_providers):\n",
    "    hours = hours.to_frame()\n",
    "    num_providers = num_providers.to_frame()\n",
    "    df = pd.merge(left=num_providers, right=hours, how='inner', left_index=True, right_index=True)\n",
    "    return df\n",
    "\n",
    "def get_hours_per_provider(df):\n",
    "    df.columns = ['Number_Providers', 'Hours']\n",
    "    df['Hours_per_Provider'] = df['Hours'] / df['Number_Providers']\n",
    "    mean_hours_provider = df['Hours_per_Provider'].mean()\n",
    "    return df, mean_hours_provider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_holidays():\n",
    "    # make dataframe for each holiday\n",
    "    christmas_dates = ['2015-12-25', '2016-12-25', '2017-12-25']\n",
    "    new_year_dates = ['2016-01-01', '2017-01-01', '2018-01-01']\n",
    "    thanksgiving_dates = ['2015-11-26', '2016-11-24', '2017-11-23']\n",
    "    thanksgiving = pd.DataFrame({'holiday':'Thanksgiving', 'ds': pd.to_datetime(thanksgiving_dates)})\n",
    "    christmas = pd.DataFrame({'holiday':'Christams', 'ds': pd.to_datetime(christmas_dates)})\n",
    "    new_years = pd.DataFrame({'holiday':'New Years', 'ds': pd.to_datetime(new_year_dates)})\n",
    "    # combine into single holidays DataFrame\n",
    "    holidays = pd.concat([christmas, thanksgiving, new_years])\n",
    "    return holidays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_prophet_forecast_w_holidays(df, df_cols, date_hours_cols,\\\n",
    "#         pred_cols, periods, holidays, mean_hours_provider):\n",
    "#     \"\"\"\n",
    "#     Inputs:\n",
    "#         df: dataframe containing timeseries and weekly hours\n",
    "#         date_hours_cols: (list) names for columns containing the date and weekly hours data\n",
    "#         pred_cols: (list) name of columns containing estimated hours, upper and lower limits\n",
    "#         of estimates\n",
    "#         periods: (int) number of periods to forecast.\n",
    "#         holidays: (dataframe) of holidays with holiday names, dates (datetime\n",
    "#             format, upper and lower windows (ints, optional))\n",
    "#     Outputs:\n",
    "#         Prophet model\n",
    "#         forecast\n",
    "#         df with original data plus predictions and upper/lower predictions\n",
    "#     \"\"\"\n",
    "#     df.columns = df_cols\n",
    "#     df = df[date_hours_cols]\n",
    "#     df.columns = ['ds', 'y']\n",
    "#     model = Prophet(holidays=holidays)\n",
    "#     model.fit(df)\n",
    "#     future = model.make_future_dataframe(periods=periods)\n",
    "#     forecast = model.predict(future)\n",
    "#     df_pred = pd.concat([df, forecast[pred_cols]], axis=1)\n",
    "#     # make num providers column\n",
    "#     df_pred['Predicted_num_Providers'] = round(df_pred['yhat'] / mean_hours_provider)\n",
    "#     return model, forecast, df_pred\n",
    "\n",
    "    # predictions = forecast.iloc[-periods:]\n",
    "    # get_prophet_training_mse(df_pred, df_name, periods)\n",
    "    # get_prophet_test_mse(df_pred, df_name, periods)\n",
    "    \n",
    "def get_prophet_forecast_w_holidays(df, df_cols, date_hours_cols,\\\n",
    "        pred_cols, periods, holidays, mean_hours_provider):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "        df: dataframe containing timeseries and weekly hours\n",
    "        date_hours_cols: (list) names for columns containing the date and weekly hours data\n",
    "        pred_cols: (list) name of columns containing estimated hours, upper and lower limits\n",
    "        of estimates\n",
    "        periods: (int) number of periods to forecast.\n",
    "        holidays: (dataframe) of holidays with holiday names, dates (datetime\n",
    "            format, upper and lower windows (ints, optional))\n",
    "    Outputs:\n",
    "        Prophet model\n",
    "        forecast\n",
    "        df with original data plus predictions and upper/lower predictions\n",
    "    \"\"\"\n",
    "    df.columns = df_cols\n",
    "    df = df[date_hours_cols]\n",
    "    df.columns = ['ds', 'y']\n",
    "#     print(df)\n",
    "    model = Prophet(holidays=holidays)\n",
    "    model.fit(df)\n",
    "    future = model.make_future_dataframe(periods=periods)\n",
    "    forecast = model.predict(future)\n",
    "    forecast.index = forecast['ds']\n",
    "    forecast = forecast[pred_cols]\n",
    "    df_pred = pd.concat([df, forecast[pred_cols]], axis=1)\n",
    "    # make num providers column\n",
    "    df_pred['Predicted_num_Providers'] = round(df_pred['yhat'] / mean_hours_provider)\n",
    "    return model, forecast, df_pred\n",
    "\n",
    "def prophet_forecast_to_csv(df_pred, file_name):\n",
    "    \"\"\"Save prophet predictions in dataframe format to csv file\"\"\"\n",
    "    prediction_df.columns = ['Date', 'True_Hours', 'Predicted_Hours', 'Lower_Limit',\\\n",
    "     'Upper_Limit', 'Predicted_num_Providers']\n",
    "    prediction_df.to_csv('{}_predictions.csv'.format(file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_prophet_forecast(csv_file, category_name, date_hours_cols,\\\n",
    "        pred_cols, periods, out_csv):\n",
    "    # import provider data\n",
    "    provider = get_cleaned_provider_data(csv_file, category_name)\n",
    "    # get weekly hours data\n",
    "    provider_hours = get_provider_weekly_hours(provider)\n",
    "    # get number of providers data\n",
    "    num_provider = get_number_unique_providers(provider)\n",
    "    # merge provider dataframes\n",
    "    provider = merge_hours_and_providers(provider_hours, num_provider)\n",
    "    # get hours per provider\n",
    "    provider_df, avg_provider_hours = get_hours_per_provider(provider)\n",
    "    # add holidays\n",
    "    holidays = get_holidays()\n",
    "    # get prophet model, forecast, predictions dataframe\n",
    "    model, forecast, df_pred = get_prophet_forecast_w_holidays(provider_df,\\\n",
    "        df_cols, date_hours_cols, pred_cols, periods, holidays, avg_provider_hours)\n",
    "    prophet_forecast_to_csv(df_pred, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infile = './data/appointments_through_04-2018.csv'\n",
    "df_cols = ['Number_Providers', 'Hours', 'Hours_per_Provider', 'date']\n",
    "date_hours_cols = ['date', 'Hours']\n",
    "periods = 90\n",
    "pred_cols = ['yhat', 'yhat_lower', 'yhat_upper']\n",
    "outfile = 'dr_test_prophet_forecast.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "provider = get_cleaned_provider_data(infile, 'doctor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "provider_hours = get_provider_weekly_hours(provider)\n",
    "    # get number of providers data\n",
    "num_provider = get_number_unique_providers(provider)\n",
    "    # merge provider dataframes\n",
    "provider = merge_hours_and_providers(provider_hours, num_provider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "provider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "provider_df, avg_provider_hours = get_hours_per_provider(provider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "provider_df.index\n",
    "# avg_provider_hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "provider_df['date'] = provider_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "provider_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holidays = get_holidays()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# holidays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infile = './data/appointments_through_04-2018.csv'\n",
    "df_cols = ['Number_Providers', 'Hours', 'Hours_per_Provider', 'date']\n",
    "date_hours_cols = ['date', 'Hours']\n",
    "periods = 90\n",
    "pred_cols = ['yhat', 'yhat_lower', 'yhat_upper']\n",
    "outfile = 'dr_test_prophet_forecast.csv'\n",
    "\n",
    "model, forecast, df_pred = get_prophet_forecast_w_holidays(provider_df, df_cols, date_hours_cols,\\\n",
    "        pred_cols, periods, holidays, avg_provider_hours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_prophet_forecast(csv_file, category_name, date_hours_cols,\\\n",
    "    pred_cols, periods, out_csv):\n",
    "    # import provider data\n",
    "    provider = get_cleaned_provider_data(csv_file, category_name)\n",
    "    # get weekly hours data\n",
    "    provider_hours = get_provider_weekly_hours(provider)\n",
    "    # get number of providers data\n",
    "    num_provider = get_number_unique_providers(provider)\n",
    "    # merge provider dataframes\n",
    "    provider = merge_hours_and_providers(provider_hours, num_provider)\n",
    "    print(provider)\n",
    "    # get hours per provider\n",
    "    provider_df, avg_provider_hours = get_hours_per_provider(provider)\n",
    "    print(provider_df)\n",
    "    # add holidays\n",
    "    holidays = get_holidays()\n",
    "    # get prophet model, forecast, predictions dataframe\n",
    "#     model, forecast, df_pred = get_prophet_forecast_w_holidays(provider_df,\\\n",
    "#         df_cols, date_hours_cols, pred_cols, periods, holidays, avg_provider_hours)\n",
    "#     prophet_forecast_to_csv(df_pred, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_prophet_forecast(csv_file=infile, category_name='doctors', date_hours_cols=date_hours_cols,\\\n",
    "            pred_cols=pred_cols, periods=90, out_csv=outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infile = './data/appointments_through_04-2018.csv'\n",
    "df_cols = ['Number_Providers', 'Hours', 'Hours_per_Provider', 'date']\n",
    "date_hours_cols = ['date', 'Hours']\n",
    "periods = 90\n",
    "pred_cols = ['yhat', 'yhat_lower', 'yhat_upper']\n",
    "outfile = 'dr_test_prophet_forecast.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "run_prophet_forecast(csv_file=infile, category_name='doctors', date_hours_cols=date_hours_cols,\\\n",
    "            pred_cols=pred_cols, periods=90, out_csv=outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
