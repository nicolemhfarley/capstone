{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from statsmodels.graphics import tsaplots\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.arima_model import ARIMA, ARIMAResults, ARMA\n",
    "from statsmodels.tsa.arima_process import ArmaProcess\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "from scipy import signal\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import pyflux as pf\n",
    "\n",
    "# from .ARIMA_functions import get_ARIMA_model\n",
    "# , plot_ARIMA_model, plot_ARIMA_resids, get_ARIMA_forecast\n",
    "\n",
    "# ,\\\n",
    "# plot_data_plus_ARIMA_predictions, plot_data_plus_ARIMA_predictions, test_rolling_ARIMA_forecast,\\\n",
    "# plot_rolling_ARIMA_forecast, get_predictions_df_and_plot_rolling_ARIMA_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.rcParams.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load timeseries_functions.py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from statsmodels.graphics import tsaplots\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# plt.rcParams.keys()\n",
    "params = {'figure.figsize': [8,8],'axes.grid.axis': 'both', 'axes.labelsize': 'Medium', 'font.size': 12.0, \\\n",
    "'lines.linewidth': 2}\n",
    "\n",
    "\n",
    "def index_to_datetime(series):\n",
    "    \"Converts series object indext to datetime\"\n",
    "    series.index = pd.to_datetime(series.index, errors='coerce')\n",
    "\n",
    "def downsample_data_week(data, fill_method='bfill'):\n",
    "    downsampled = data.resample(rule='W').mean()\n",
    "    downsampled.fillna(method=fill_method, inplace=True)\n",
    "    return downsampled\n",
    "\n",
    "def plot_series(series, xlabel, ylabel, plot_name):\n",
    "    \"Plots simple time series from Pandas Series\"\n",
    "    ax = series.plot(figsize=(8,3), linewidth = 3, fontsize=10, grid=True, rot=30)\n",
    "    ax.set_title(plot_name, fontsize=18)\n",
    "    ax.set_xlabel(xlabel, fontsize=15)\n",
    "    ax.set_ylabel(ylabel, fontsize=15)\n",
    "    plt.show()\n",
    "\n",
    "def plot_series_and_differences(series, ax, num_diff, params, title=''):\n",
    "    \"Plot raw data and specified number of differences\"\n",
    "    plt.rcParams.update(params)\n",
    "    ax[0].plot(series.index, series)\n",
    "    ax[0].set_title('Raw series: {}'.format(title))\n",
    "    for i in range(1, num_diff+1):\n",
    "        diff = series.diff(i)\n",
    "        ax[i].plot(series.index, diff)\n",
    "        ax[i].set_title('Difference # {}'.format(str(i)))\n",
    "\n",
    "def run_augmented_Dickey_Fuller_test(series, num_diffs=None):\n",
    "    \"Test for stationarity on raw data and specified number of differences.\"\n",
    "    test = sm.tsa.stattools.adfuller(series)\n",
    "    if test[1] >= 0.05:\n",
    "        print('The p-value for the series is: {p}, which is not significant'.\\\n",
    "        format(p=test[1]))\n",
    "    else:\n",
    "        print('The p-value for the series is: {p}, which is significant'.\\\n",
    "        format(p=test[1]))\n",
    "    if num_diffs:\n",
    "        for i in range(1, num_diffs +1):\n",
    "            test = sm.tsa.stattools.adfuller(series.diff(i)[i:])\n",
    "            if test[1] >= 0.05:\n",
    "                print('The p-value for difference {diff} is: {p}, which is not \\\\\n",
    "                 significant'.format(diff=str(i), p=test[1]))\n",
    "            else:\n",
    "                print('The p-value for difference {diff} is: {p}, which is \\\\\n",
    "                 significant'.format(diff=str(i), p=test[1]))\n",
    "\n",
    "def plot_autocorrelation(series, params, lags, alpha, title=''):\n",
    "    plt.rcParams.update(params)\n",
    "    acf_plot = tsaplots.plot_acf(series, lags=lags, alpha=alpha)\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Number of Lags')\n",
    "    plt.show()\n",
    "\n",
    "def plot_partial_autocorrelation(series, params, lags, alpha, title=''):\n",
    "    plt.rcParams.update(params)\n",
    "    acf_plot = tsaplots.plot_pacf(series, lags=lags, alpha=alpha)\n",
    "    plt.xlabel('Number of Lags')\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "def plot_decomposition(series, params, freq, title=''):\n",
    "    \"Plots observed, trend, seasonal, residual\"\n",
    "    plt.rcParams.update(params)\n",
    "    decomp = sm.tsa.seasonal_decompose(series, freq=freq)\n",
    "    fig = decomp.plot()\n",
    "    plt.title(title)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plt.rcParams.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dr = pd.read_csv('all_dr_hours.csv', index_col=0, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_RN_PA = pd.read_csv('all_RN_PA_hours.csv', index_col=0, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_therapist = pd.read_csv('all_therapist_hours.csv',index_col=0, header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Long Short-Term Memory network (LSTM)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "see: https://machinelearningmastery.com/time-series-prediction-lstm-recurrent-neural-networks-python-keras/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try with just Dr data\n",
    "plot_series(all_dr, xlabel='Date', ylabel='Hours per Week', plot_name='Doctors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = all_dr.values\n",
    "# reshape to 2D array\n",
    "data = data.reshape(-1,1)\n",
    "# scale/normalize data\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "data = scaler.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into training and test sets\n",
    "train_size = int(len(data) * 0.67)\n",
    "test_size = len(data) - train_size\n",
    "train, test = data[0:train_size,:], data[train_size:len(data),:]\n",
    "train, test = data[0:train_size,:], data[train_size:len(data),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert data values into dataset matrix\n",
    "def create_dataset(data, num_steps=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(data)-num_steps-1):\n",
    "        a = data[i:(i+num_steps),0]\n",
    "        dataX.append(a)\n",
    "        dataY.append(data[i + num_steps, 0])\n",
    "    return np.array(dataX), np.array(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_steps=1\n",
    "trainX, trainY = create_dataset(train, num_steps)\n",
    "testX, testY = create_dataset(test, num_steps)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# LSTM network expects the input data (X) to be provided with a specific\n",
    "# array structure in the form of: [samples, time steps, features]\n",
    "# reshape data to be [samples, time steps, features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainX = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "testX = np.reshape(testX, (testX.shape[0], 1, testX.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create and fit LSTM network\n",
    "model = Sequential()\n",
    "model.add(LSTM(4, input_shape=(1, num_steps)))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(trainX, trainY, epochs=100, batch_size=1, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get predictions\n",
    "trainPredict = model.predict(trainX)\n",
    "testPredict = model.predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# invert predictions\n",
    "trainPredict = scaler.inverse_transform(trainPredict)\n",
    "trainY = scaler.inverse_transform([trainY])\n",
    "testPredict = scaler.inverse_transform(testPredict)\n",
    "testY = scaler.inverse_transform([testY])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate root mean squared error\n",
    "trainScore = math.sqrt(mean_squared_error(trainY[0], trainPredict[:,0]))\n",
    "print('Train Score: %.2f RMSE' % (trainScore))\n",
    "testScore = math.sqrt(mean_squared_error(testY[0], testPredict[:,0]))\n",
    "print('Test Score: %.2f RMSE' % (testScore))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#shift train and test predictions for plotting\n",
    "trainPredictPlot = np.empty_like(data)\n",
    "trainPredictPlot[:, :] = np.nan\n",
    "trainPredictPlot[num_steps:len(trainPredict)+num_steps, :] = trainPredict\n",
    "testPredictPlot = np.empty_like(data)\n",
    "testPredictPlot[:, :] = np.nan\n",
    "testPredictPlot[len(trainPredict)+(num_steps*2)+1:len(data)-1, :] = testPredict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot baseline and predictions\n",
    "params = {'figure.figsize': [10,10],'axes.grid': False,'axes.grid.axis': 'both', 'axes.labelsize': 'Medium', 'font.size': 12.0, \\\n",
    "'lines.linewidth': 2}\n",
    "plt.rcParams.update(params)\n",
    "plt.plot(scaler.inverse_transform(data), label='actual')\n",
    "plt.plot(trainPredictPlot, linestyle='--',  label='predicted')\n",
    "plt.plot(testPredictPlot, linestyle='--', label='predicted')\n",
    "plt.ylabel('Hours per Week')\n",
    "plt.title('Doctors LSTM Model')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_and_reshape_data(data, split_at=0.67, num_steps=1):\n",
    "    train_size = int(len(data) * 0.67)\n",
    "    test_size = len(data) - train_size\n",
    "    train, test = data[0:train_size,:], data[train_size:len(data),:]\n",
    "    train, test = data[0:train_size,:], data[train_size:len(data),:]\n",
    "    trainX, trainY = create_dataset(train, num_steps)\n",
    "    testX, testY = create_dataset(test, num_steps)\n",
    "    trainX = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "    testX = np.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n",
    "    return trainX, trainY, testX, testY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_sequential_LSTM(trainX, trainY, add_layers=4, input_shape=(1,1),\\\n",
    "                        density=1, epochs=100, batch_size=1, optimizer='adam', verbose=2, \\\n",
    "                        loss='mean_squared_error'):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(add_layers, input_shape=input_shape))\n",
    "    model.add(Dense(density))\n",
    "    model.compile(loss=loss, optimizer=optimizer)\n",
    "    model.fit(trainX, trainY, epochs=epochs, batch_size=batch_size, verbose=verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_LSTM_predictions_and_inversions(trainX, testX):\n",
    "    trainPredict = model.predict(trainX)\n",
    "    testPredict = model.predict(testX)\n",
    "    return trainPredict, testPredict\n",
    "\n",
    "def inverse_transform(trainY, testY, trainPredict, testPredict):    \n",
    "    trainPredict = scaler.inverse_transform(trainPredict)\n",
    "    trainY = scaler.inverse_transform([trainY])\n",
    "    testPredict = scaler.inverse_transform(testPredict)\n",
    "    testY = scaler.inverse_transform([testY])\n",
    "    return trainY, testY, trainPredict, testPredict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_RMSE(trainY, testY, trainPredict, testPredict):\n",
    "    trainScore = math.sqrt(mean_squared_error(trainY[0], trainPredict[:,0]))\n",
    "    print('Train Score: %.2f RMSE' % (trainScore))\n",
    "    testScore = math.sqrt(mean_squared_error(testY[0], testPredict[:,0]))\n",
    "    print('Test Score: %.2f RMSE' % (testScore))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prep_predictions_for_plotting(data, trainPredict, testPredict, num_steps=1):\n",
    "    trainPredictPlot = np.empty_like(data)\n",
    "    trainPredictPlot[:, :] = np.nan\n",
    "    trainPredictPlot[num_steps:len(trainPredict)+num_steps, :] = trainPredict\n",
    "    testPredictPlot = np.empty_like(data)\n",
    "    testPredictPlot[:, :] = np.nan\n",
    "    testPredictPlot[len(trainPredict)+(num_steps*2)+1:len(data)-1, :] = testPredict\n",
    "    return trainPredictPlot, testPredictPlot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_data_LSTM_predictions(data, trainPredictPlot, testPredictPlot,\\\n",
    "                               params,title='', ylabel=''):\n",
    "    fig = plt.figure()\n",
    "    plt.rcParams.update(params)\n",
    "    plt.plot(scaler.inverse_transform(data), label='actual')\n",
    "    plt.plot(trainPredictPlot, linestyle='--',  label='predicted')\n",
    "    plt.plot(testPredictPlot, linestyle='--', label='predicted')\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    return "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### for RN/PA category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = all_RN_PA.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape to 2D array\n",
    "data = data.reshape(-1,1)\n",
    "# scale/normalize data\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "data = scaler.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainX, trainY, testX, testY = split_and_reshape_data(data, split_at=0.67, num_steps=1)\n",
    "\n",
    "fit_sequential_LSTM(trainX, trainY, add_layers=4, input_shape=(1,1),\\\n",
    "                        density=1, epochs=100, batch_size=1, optimizer='adam', verbose=2, \\\n",
    "                        loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainPredict, testPredict = get_LSTM_predictions_and_inversions(trainX, testX)\n",
    "\n",
    "trainY, testY, trainPredict, testPredict = inverse_transform(trainY, testY, trainPredict, testPredict)\n",
    "\n",
    "trainPredictPlot, testPredictPlot = prep_predictions_for_plotting(data, trainPredict, testPredict, num_steps=1)\n",
    "\n",
    "plot_data_LSTM_predictions(data, trainPredictPlot, testPredictPlot,\\\n",
    "            params,title='RN/PA LSTM Model', ylabel='Hours per Week')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Therapists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = all_therapist.values\n",
    "# reshape to 2D array\n",
    "data = data.reshape(-1,1)\n",
    "# scale/normalize data\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "data = scaler.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainX, trainY, testX, testY = split_and_reshape_data(data, split_at=0.67, num_steps=1)\n",
    "\n",
    "fit_sequential_LSTM(trainX, trainY, add_layers=4, input_shape=(1,1),\\\n",
    "                        density=1, epochs=100, batch_size=1, optimizer='adam', verbose=2, \\\n",
    "                        loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "trainPredict, testPredict = get_LSTM_predictions_and_inversions(trainX, testX)\n",
    "\n",
    "# calculate_RMSE(trainY, testY, trainPredict, testPredict)\n",
    "\n",
    "trainY, testY, trainPredict, testPredict = inverse_transform(trainY, testY, trainPredict, testPredict)\n",
    "\n",
    "trainPredictPlot, testPredictPlot = prep_predictions_for_plotting(data, trainPredict, testPredict, num_steps=1)\n",
    "\n",
    "plot_data_LSTM_predictions(data, trainPredictPlot, testPredictPlot,\\\n",
    "                        params,title='Therapists LSTM Model', ylabel='Hours per Week')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
